#!/usr/bin/env python3
"""
æ„å›¾è¯†åˆ«é¡¹ç›®å¿«é€Ÿå¼€å§‹è„šæœ¬
ä¸€é”®å®Œæˆæ•°æ®å‡†å¤‡ã€è®­ç»ƒå’Œè¯„ä¼°
"""

import os
import sys
import subprocess
import json
from pathlib import Path

class IntentRecognitionQuickStart:
    """æ„å›¾è¯†åˆ«å¿«é€Ÿå¼€å§‹ç±»"""
    
    def __init__(self, workspace_root: str = "/workspace"):
        self.workspace_root = workspace_root
        self.project_root = f"{workspace_root}/intent_recognition"
        self.llamafactory_root = f"{workspace_root}/LLaMA-Factory"
        
        # æ£€æŸ¥å¿…è¦è·¯å¾„
        self.check_environment()
    
    def check_environment(self):
        """æ£€æŸ¥ç¯å¢ƒæ˜¯å¦å°±ç»ª"""
        print("=== ç¯å¢ƒæ£€æŸ¥ ===")
        
        # æ£€æŸ¥ LLaMA-Factory
        if not os.path.exists(self.llamafactory_root):
            print("âŒ LLaMA-Factory ä¸å­˜åœ¨")
            return False
        
        # æ£€æŸ¥æ¨¡å‹
        model_path = f"{self.workspace_root}/models/DeepSeek-R1-Distill-Qwen-1.5B"
        if not os.path.exists(model_path):
            print("âŒ DeepSeek-R1-Distill-Qwen-1.5B æ¨¡å‹ä¸å­˜åœ¨")
            return False
        
        print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
        return True
    
    def step1_prepare_data(self):
        """æ­¥éª¤1: æ•°æ®å‡†å¤‡"""
        print("\n=== æ­¥éª¤1: æ•°æ®å‡†å¤‡ ===")
        
        try:
            # è¿è¡Œæ•°æ®ä¸‹è½½è„šæœ¬
            print("ä¸‹è½½ç¤ºä¾‹æ•°æ®é›†...")
            subprocess.run([
                sys.executable, 
                f"{self.project_root}/scripts/download_dataset.py"
            ], check=True, input="4\n", text=True)  # é€‰æ‹©4ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®
            
            # è¿è¡Œæ•°æ®é¢„å¤„ç†è„šæœ¬
            print("é¢„å¤„ç†æ•°æ®...")
            subprocess.run([
                sys.executable,
                f"{self.project_root}/scripts/preprocess_data.py"
            ], check=True)
            
            print("âœ… æ•°æ®å‡†å¤‡å®Œæˆ")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            return False
    
    def step2_train_model(self):
        """æ­¥éª¤2: æ¨¡å‹è®­ç»ƒ"""
        print("\n=== æ­¥éª¤2: æ¨¡å‹è®­ç»ƒ ===")
        
        try:
            # åˆ‡æ¢åˆ° LLaMA-Factory ç›®å½•å¹¶è¿è¡Œè®­ç»ƒ
            config_path = f"{self.project_root}/config/model_config.yaml"
            
            print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
            cmd = [
                sys.executable, 
                "-m", "llamafactory.cli.train",
                config_path
            ]
            
            # è®¾ç½®ç¯å¢ƒå˜é‡å¹¶è¿è¡Œ
            env = os.environ.copy()
            env["PYTHONPATH"] = f"{self.llamafactory_root}:{env.get('PYTHONPATH', '')}"
            
            result = subprocess.run(
                cmd, 
                cwd=self.llamafactory_root,
                env=env,
                capture_output=True,
                text=True,
                timeout=3600  # 1å°æ—¶è¶…æ—¶
            )
            
            if result.returncode == 0:
                print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
                return True
            else:
                print(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥:")
                print(result.stderr)
                return False
                
        except subprocess.TimeoutExpired:
            print("âŒ è®­ç»ƒè¶…æ—¶ï¼ˆè¶…è¿‡1å°æ—¶ï¼‰")
            return False
        except Exception as e:
            print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    def step3_evaluate_model(self):
        """æ­¥éª¤3: æ¨¡å‹è¯„ä¼°"""
        print("\n=== æ­¥éª¤3: æ¨¡å‹è¯„ä¼° ===")
        
        try:
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è®­ç»ƒå®Œæˆ
            model_path = f"{self.project_root}/outputs/models/intent_recognition_lora"
            if not os.path.exists(model_path):
                print("âŒ è®­ç»ƒå®Œæˆçš„æ¨¡å‹ä¸å­˜åœ¨")
                return False
            
            # è¿è¡Œè¯„ä¼°è„šæœ¬
            test_data_path = f"{self.project_root}/data/processed/intent_test.json"
            output_dir = f"{self.project_root}/outputs/evaluations"
            
            cmd = [
                sys.executable,
                f"{self.project_root}/scripts/evaluate.py",
                "--model_path", model_path,
                "--test_data", test_data_path,
                "--output_dir", output_dir
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print("âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ")
                print(result.stdout)
                
                # æ˜¾ç¤ºè¯„ä¼°ç»“æœæ–‡ä»¶
                results_file = f"{output_dir}/evaluation_results.json"
                if os.path.exists(results_file):
                    with open(results_file, 'r', encoding='utf-8') as f:
                        results = json.load(f)
                    print(f"\nğŸ“Š è¯„ä¼°æ‘˜è¦:")
                    print(f"å‡†ç¡®ç‡: {results['accuracy']:.4f}")
                    print(f"ç²¾ç¡®ç‡: {results['precision']:.4f}")
                    print(f"å¬å›ç‡: {results['recall']:.4f}")
                    print(f"F1åˆ†æ•°: {results['f1_score']:.4f}")
                
                return True
            else:
                print(f"âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥:")
                print(result.stderr)
                return False
                
        except Exception as e:
            print(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    def step4_test_inference(self):
        """æ­¥éª¤4: æ¨ç†æµ‹è¯•"""
        print("\n=== æ­¥éª¤4: æ¨ç†æµ‹è¯• ===")
        
        try:
            # è¿è¡Œæ¨ç†ç¤ºä¾‹
            subprocess.run([
                sys.executable,
                f"{self.project_root}/examples/inference_example.py"
            ], check=True)
            
            print("âœ… æ¨ç†æµ‹è¯•å®Œæˆ")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def run_all_steps(self):
        """è¿è¡Œæ‰€æœ‰æ­¥éª¤"""
        print("ğŸš€ å¼€å§‹æ„å›¾è¯†åˆ«é¡¹ç›®å¿«é€Ÿå¯åŠ¨")
        print("è¿™å°†ä¾æ¬¡æ‰§è¡Œï¼šæ•°æ®å‡†å¤‡ -> æ¨¡å‹è®­ç»ƒ -> æ¨¡å‹è¯„ä¼° -> æ¨ç†æµ‹è¯•")
        
        steps = [
            ("æ•°æ®å‡†å¤‡", self.step1_prepare_data),
            ("æ¨¡å‹è®­ç»ƒ", self.step2_train_model),
            ("æ¨¡å‹è¯„ä¼°", self.step3_evaluate_model),
            ("æ¨ç†æµ‹è¯•", self.step4_test_inference)
        ]
        
        results = {}
        
        for step_name, step_func in steps:
            try:
                results[step_name] = step_func()
            except Exception as e:
                print(f"âŒ {step_name}æ­¥éª¤å‡ºç°å¼‚å¸¸: {e}")
                results[step_name] = False
            
            if not results[step_name]:
                print(f"\nâš ï¸  {step_name}å¤±è´¥ï¼Œç»ˆæ­¢åç»­æ­¥éª¤")
                break
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        self.show_final_results(results)
    
    def show_final_results(self, results: dict):
        """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
        print("\n" + "="*50)
        print("ğŸ“‹ æ‰§è¡Œç»“æœæ±‡æ€»:")
        print("="*50)
        
        for step_name, success in results.items():
            status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
            print(f"{step_name:<15}: {status}")
        
        # å¦‚æœæ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸï¼Œæ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        if all(results.values()):
            print(f"\nğŸ‰ æ­å–œï¼æ‰€æœ‰æ­¥éª¤æ‰§è¡ŒæˆåŠŸï¼")
            print(f"\nğŸ“ é¡¹ç›®æ–‡ä»¶ä½ç½®:")
            print(f"  é¡¹ç›®ç›®å½•: {self.project_root}")
            print(f"  è®­ç»ƒæ¨¡å‹: {self.project_root}/outputs/models/intent_recognition_lora")
            print(f"  è¯„ä¼°ç»“æœ: {self.project_root}/outputs/evaluations")
            print(f"  æ•°æ®æ–‡ä»¶: {self.project_root}/data/processed")
            
            print(f"\nğŸ”§ ä¸‹ä¸€æ­¥å¯ä»¥:")
            print(f"1. æŸ¥çœ‹è¯„ä¼°æŠ¥å‘Š: {self.project_root}/outputs/evaluations/evaluation_results.json")
            print(f"2. è¿è¡Œäº¤äº’å¼æµ‹è¯•: python {self.project_root}/examples/inference_example.py")
            print(f"3. å¯åŠ¨APIæœåŠ¡: cd {self.llamafactory_root} && python src/api.py")
            print(f"4. ä½¿ç”¨APIæµ‹è¯•: python {self.project_root}/examples/api_example.py")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ„å›¾è¯†åˆ«å¿«é€Ÿå¯åŠ¨è„šæœ¬")
    parser.add_argument("--step", choices=["1", "2", "3", "4", "all"], default="all",
                       help="æ‰§è¡Œç‰¹å®šæ­¥éª¤ï¼Œé»˜è®¤æ‰§è¡Œæ‰€æœ‰æ­¥éª¤")
    
    args = parser.parse_args()
    
    quick_start = IntentRecognitionQuickStart()
    
    if args.step == "all":
        quick_start.run_all_steps()
    else:
        step_map = {
            "1": ("æ•°æ®å‡†å¤‡", quick_start.step1_prepare_data),
            "2": ("æ¨¡å‹è®­ç»ƒ", quick_start.step2_train_model),
            "3": ("æ¨¡å‹è¯„ä¼°", quick_start.step3_evaluate_model),
            "4": ("æ¨ç†æµ‹è¯•", quick_start.step4_test_inference)
        }
        
        if args.step in step_map:
            step_name, step_func = step_map[args.step]
            print(f"ğŸš€ æ‰§è¡Œæ­¥éª¤{args.step}: {step_name}")
            
            try:
                success = step_func()
                if success:
                    print(f"âœ… {step_name}å®Œæˆ")
                else:
                    print(f"âŒ {step_name}å¤±è´¥")
            except Exception as e:
                print(f"âŒ {step_name}å‡ºç°å¼‚å¸¸: {e}")

if __name__ == "__main__":
    main()
# æ„å›¾è¯†åˆ«é¡¹ç›®ä½¿ç”¨æŒ‡å—

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®åŸºäº LLaMA-Factory æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºè®­ç»ƒé«˜æ•ˆçš„æ„å›¾è¯†åˆ«æ¨¡å‹ã€‚æ”¯æŒå¤šç§å¼€æºæ•°æ®é›†ï¼Œæä¾›å®Œæ•´çš„è®­ç»ƒã€è¯„ä¼°å’Œéƒ¨ç½²æµç¨‹ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ä¸€é”®å¯åŠ¨ï¼ˆæ¨èï¼‰

```bash
cd /workspace/intent_recognition
python quick_start.py
```

è¿™å°†è‡ªåŠ¨å®Œæˆï¼š
1. âœ… æ•°æ®å‡†å¤‡
2. âœ… æ¨¡å‹è®­ç»ƒ  
3. âœ… æ¨¡å‹è¯„ä¼°
4. âœ… æ¨ç†æµ‹è¯•

### åˆ†æ­¥éª¤æ‰§è¡Œ

å¦‚æœéœ€è¦åˆ†æ­¥æ‰§è¡Œæˆ–è°ƒè¯•ï¼š

```bash
# æ­¥éª¤1: æ•°æ®å‡†å¤‡
python quick_start.py --step 1

# æ­¥éª¤2: æ¨¡å‹è®­ç»ƒ
python quick_start.py --step 2

# æ­¥éª¤3: æ¨¡å‹è¯„ä¼°
python quick_start.py --step 3

# æ­¥éª¤4: æ¨ç†æµ‹è¯•
python quick_start.py --step 4
```

## ğŸ“Š æ•°æ®é›†é…ç½®

### æ”¯æŒçš„æ•°æ®é›†

1. **ATIS** - èˆªç©ºé¢†åŸŸæ„å›¾è¯†åˆ«
   - 26ç§æ„å›¾ç±»å‹
   - 5,000+è®­ç»ƒæ ·æœ¬

2. **SNIPS** - æ™ºèƒ½åŠ©æ‰‹æ„å›¾è¯†åˆ«  
   - 7ç§æ ¸å¿ƒæ„å›¾
   - 13,000+è®­ç»ƒæ ·æœ¬

3. **CrossWOZ** - ä¸­æ–‡å¤šé¢†åŸŸå¯¹è¯
   - 5ä¸ªé¢†åŸŸï¼šé¤é¥®ã€ç”µå½±ã€é…’åº—ç­‰
   - 30,000+è¯­å¥

4. **è‡ªå®šä¹‰æ•°æ®** - ç¤ºä¾‹æ•°æ®é›†
   - 25ç§å¸¸è§æ„å›¾
   - é€‚åˆå¿«é€Ÿæµ‹è¯•

### æ„å›¾ç±»å‹å®šä¹‰

```json
[
  "query_flight",      // æŸ¥è¯¢èˆªç­
  "book_flight",        // é¢„è®¢èˆªç­
  "cancel_flight",      // å–æ¶ˆèˆªç­
  "query_weather",      // æŸ¥è¯¢å¤©æ°”
  "set_reminder",       // è®¾ç½®æé†’
  "play_music",         // æ’­æ”¾éŸ³ä¹
  "send_message",       // å‘é€æ¶ˆæ¯
  "make_call",          // æ‰“ç”µè¯
  "search_info",        // æœç´¢ä¿¡æ¯
  "navigation",         // å¯¼èˆª
  "restaurant_booking", // é¤å…é¢„è®¢
  "movie_booking",      // ç”µå½±é¢„è®¢
  "hotel_booking",      // é…’åº—é¢„è®¢
  "shopping",           // è´­ç‰©
  "translation",        // ç¿»è¯‘
  "calculator",         // è®¡ç®—å™¨
  "timer",              // è®¡æ—¶å™¨
  "alarm",              // é—¹é’Ÿ
  "note",               // ç¬”è®°
  "calendar",           // æ—¥å†
  "email",              // é‚®ä»¶
  "file_management",    // æ–‡ä»¶ç®¡ç†
  "system_control",     // ç³»ç»Ÿæ§åˆ¶
  "general_chat",       // é€šç”¨èŠå¤©
  "greeting",           // é—®å€™
  "goodbye"             // å‘Šåˆ«
]
```

## ğŸ› ï¸ è®­ç»ƒé…ç½®

### æ¨¡å‹é…ç½® (config/model_config.yaml)

```yaml
# åŸºç¡€ LoRA å¾®è°ƒé…ç½®
model_name_or_path: /workspace/models/DeepSeek-R1-Distill-Qwen-1.5B
template: qwen
finetuning_type: lora
lora_rank: 8
lora_alpha: 16
learning_rate: 5.0e-5
num_train_epochs: 3.0
```

### é«˜çº§è®­ç»ƒé…ç½® (config/training_config.yaml)

```yaml
# QLoRA é‡åŒ–å¾®è°ƒé…ç½®
quantization_bit: 4
gradient_checkpointing: true
per_device_train_batch_size: 2
gradient_accumulation_steps: 8
```

## ğŸ“ˆ æ¨¡å‹è¯„ä¼°

### è‡ªåŠ¨è¯„ä¼°

```bash
python scripts/evaluate.py \
  --model_path outputs/models/intent_recognition_lora \
  --test_data data/processed/intent_test.json \
  --output_dir outputs/evaluations
```

### è¯„ä¼°æŒ‡æ ‡

- **å‡†ç¡®ç‡** (Accuracy) > 90%
- **ç²¾ç¡®ç‡** (Precision) > 85%
- **å¬å›ç‡** (Recall) > 85%
- **F1 åˆ†æ•°** (F1-Score) > 85%

### å¯è§†åŒ–ç»“æœ

è¯„ä¼°å®Œæˆåä¼šç”Ÿæˆï¼š
- `confusion_matrix.png` - æ··æ·†çŸ©é˜µå›¾
- `metrics.png` - è¯„ä¼°æŒ‡æ ‡å›¾
- `evaluation_results.json` - è¯¦ç»†ç»“æœ
- `predictions.json` - é¢„æµ‹è¯¦æƒ…

## ğŸš€ éƒ¨ç½²ä½¿ç”¨

### 1. Python æ¨ç†

```python
from examples.inference_example import IntentRecognitionModel

# åŠ è½½æ¨¡å‹
model = IntentRecognitionModel("outputs/models/intent_recognition_lora")

# å•ä¸ªé¢„æµ‹
intent = model.predict_intent("å¸®æˆ‘æŸ¥è¯¢æ˜å¤©åŒ—äº¬åˆ°ä¸Šæµ·çš„èˆªç­")
print(f"æ„å›¾: {intent}")  # è¾“å‡º: query_flight

# æ‰¹é‡é¢„æµ‹
texts = ["æŸ¥è¯¢å¤©æ°”", "æ’­æ”¾éŸ³ä¹", "é¢„è®¢é¤å…"]
intents = model.batch_predict(texts)
```

### 2. API æœåŠ¡

#### å¯åŠ¨æœåŠ¡

```bash
cd /workspace/LLaMA-Factory
python src/api.py
```

#### è°ƒç”¨ API

```python
from examples.api_example import IntentRecognitionAPI

api = IntentRecognitionAPI("http://localhost:8000")
response = api.recognize_intent("å¸®æˆ‘è®¾ç½®ä¸€ä¸ªé—¹é’Ÿ")
intent = api.extract_intent_from_response(response)
```

### 3. äº¤äº’å¼æµ‹è¯•

```bash
# æ¨¡å‹æ¨ç†æµ‹è¯•
python examples/inference_example.py

# API æ¥å£æµ‹è¯•  
python examples/api_example.py

# æ¨¡å‹äº¤äº’å¼è¯„ä¼°
python scripts/evaluate.py --model_path outputs/models/intent_recognition_lora --interactive
```

## ğŸ“ æ–‡ä»¶ç»“æ„è¯´æ˜

```
intent_recognition/
â”œâ”€â”€ README.md                    # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ ä½¿ç”¨æŒ‡å—.md                 # æœ¬ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ quick_start.py              # ä¸€é”®å¯åŠ¨è„šæœ¬
â”œâ”€â”€ config/                     # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ model_config.yaml       # åŸºç¡€è®­ç»ƒé…ç½®
â”‚   â”œâ”€â”€ dataset_config.yaml     # æ•°æ®é›†é…ç½®
â”‚   â””â”€â”€ training_config.yaml    # é«˜çº§è®­ç»ƒé…ç½®
â”œâ”€â”€ data/                       # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ raw/                    # åŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ processed/              # å¤„ç†åæ•°æ®
â”‚   â””â”€â”€ dataset_info.json       # LLaMA-Factory æ•°æ®é›†é…ç½®
â”œâ”€â”€ scripts/                    # è„šæœ¬ç›®å½•
â”‚   â”œâ”€â”€ download_dataset.py     # æ•°æ®ä¸‹è½½è„šæœ¬
â”‚   â”œâ”€â”€ preprocess_data.py      # æ•°æ®é¢„å¤„ç†è„šæœ¬
â”‚   â””â”€â”€ evaluate.py             # æ¨¡å‹è¯„ä¼°è„šæœ¬
â”œâ”€â”€ outputs/                    # è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ models/                 # è®­ç»ƒå®Œæˆçš„æ¨¡å‹
â”‚   â”œâ”€â”€ logs/                   # è®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ evaluations/            # è¯„ä¼°ç»“æœ
â””â”€â”€ examples/                   # ç¤ºä¾‹ç›®å½•
    â”œâ”€â”€ inference_example.py    # æ¨ç†ç¤ºä¾‹
    â””â”€â”€ api_example.py         # API ä½¿ç”¨ç¤ºä¾‹
```

## ğŸ”§ è‡ªå®šä¹‰é…ç½®

### 1. æ·»åŠ æ–°çš„æ„å›¾ç±»å‹

1. åœ¨ `config/dataset_config.yaml` ä¸­æ·»åŠ æ„å›¾ç±»å‹
2. å‡†å¤‡å¯¹åº”çš„æ•°æ®æ ·æœ¬
3. é‡æ–°è¿è¡Œè®­ç»ƒæµç¨‹

### 2. ä½¿ç”¨ä¸åŒçš„åŸºç¡€æ¨¡å‹

ä¿®æ”¹ `config/model_config.yaml` ä¸­çš„æ¨¡å‹è·¯å¾„ï¼š

```yaml
# ä½¿ç”¨ Qwen2.5-7B
model_name_or_path: /workspace/models/Qwen2.5-7B-Instruct

# ä½¿ç”¨å…¶ä»–æ¨¡å‹
model_name_or_path: /path/to/your/model
```

### 3. è°ƒæ•´è®­ç»ƒå‚æ•°

åœ¨é…ç½®æ–‡ä»¶ä¸­è°ƒæ•´ä»¥ä¸‹å‚æ•°ï¼š

```yaml
# æ‰¹æ¬¡å¤§å°ï¼ˆæ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼‰
per_device_train_batch_size: 4

# å­¦ä¹ ç‡
learning_rate: 5.0e-5

# è®­ç»ƒè½®æ•°
num_train_epochs: 3.0

# LoRA å‚æ•°
lora_rank: 8
lora_alpha: 16
```

## âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. å†…å­˜ä¼˜åŒ–

- ä½¿ç”¨ QLoRA é‡åŒ–ï¼š`quantization_bit: 4`
- å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼š`gradient_checkpointing: true`
- å‡å°æ‰¹æ¬¡å¤§å°ï¼š`per_device_train_batch_size: 2`

### 2. è®­ç»ƒåŠ é€Ÿ

- ä½¿ç”¨å¤š GPUï¼šé…ç½® `CUDA_VISIBLE_DEVICES`
- å¢åŠ æ¢¯åº¦ç´¯ç§¯ï¼š`gradient_accumulation_steps: 8`
- å¯ç”¨æ··åˆç²¾åº¦ï¼š`fp16: true`

### 3. æ¨ç†ä¼˜åŒ–

- æ¨¡å‹é‡åŒ–ï¼š`bitsandbytes` 4bit/8bit é‡åŒ–
- æ‰¹é‡æ¨ç†ï¼šä½¿ç”¨ `batch_predict` æ–¹æ³•
- ç¼“å­˜æœºåˆ¶ï¼šå¯¹é¢‘ç¹æŸ¥è¯¢çš„ç»“æœè¿›è¡Œç¼“å­˜

## ğŸ› å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒæ—¶æ˜¾å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆï¼š**
```yaml
# ä½¿ç”¨é‡åŒ–è®­ç»ƒ
quantization_bit: 4
# å‡å°æ‰¹æ¬¡å¤§å°
per_device_train_batch_size: 1
# å¢åŠ æ¢¯åº¦ç´¯ç§¯
gradient_accumulation_steps: 16
```

### Q2: æ¨¡å‹å‡†ç¡®ç‡ä½

**è§£å†³æ–¹æ¡ˆï¼š**
- å¢åŠ è®­ç»ƒæ•°æ®é‡
- è°ƒæ•´å­¦ä¹ ç‡å’Œè®­ç»ƒè½®æ•°
- æ£€æŸ¥æ•°æ®è´¨é‡ï¼Œå»é™¤å™ªå£°
- å°è¯•ä¸åŒçš„ LoRA å‚æ•°

### Q3: API æœåŠ¡å¯åŠ¨å¤±è´¥

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
lsof -i :8000
# ä½¿ç”¨ä¸åŒç«¯å£
API_PORT=8001 python src/api.py
```

## ğŸ“š æ›´å¤šèµ„æº

- [LLaMA-Factory å®˜æ–¹æ–‡æ¡£](https://llamafactory.readthedocs.io/)
- [DeepSeek æ¨¡å‹æ–‡æ¡£](https://huggingface.co/deepseek-ai)
- [Qwen æ¨¡å‹æ–‡æ¡£](https://huggingface.co/Qwen)

## ğŸ¤ æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š
1. æ£€æŸ¥ç¯å¢ƒé…ç½®æ˜¯å¦æ­£ç¡®
2. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
3. å°è¯•ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæµ‹è¯•
4. å‚è€ƒæœ¬æ–‡æ¡£çš„å¸¸è§é—®é¢˜è§£ç­”

---

**ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼ğŸ‰**